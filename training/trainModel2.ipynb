{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f777e349",
   "metadata": {},
   "source": [
    "# Code for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faraboli\\AppData\\Local\\miniconda3\\envs\\bubbleid\\lib\\site-packages\\detectron2\\model_zoo\\model_zoo.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries:\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2.data import transforms as T\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml, copy\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo, structures\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "\n",
    "import labelme2cocoMy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c498fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on modifie les fichiers importer il faut forcer a les recharger pour que les modifs soient prises en compte\n",
    "from importlib import reload\n",
    "reload(labelme2cocoMy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235bb39",
   "metadata": {},
   "source": [
    "## Creation du fichier coco a partir des sorties de labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour le training set\n",
    "labelme_folder_path_train = \"dataset\\\\train\"\n",
    "coco_path_train = \"train.json\" # output path\n",
    "labelme2cocoMy.labelme2coco(labelme_folder_path_train, coco_path_train)\n",
    "# Et pour le validation set\n",
    "labelme_folder_path_val = \"dataset\\\\val\"\n",
    "coco_path_val = \"val.json\"\n",
    "labelme2cocoMy.labelme2coco(labelme_folder_path_val, coco_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab929e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour verifier le nombre de classe et leur numerotation\n",
    "import json\n",
    "\n",
    "with open(\"train.json\") as f:\n",
    "    data = json.load(f)\n",
    "num_classes = len(data[\"categories\"])\n",
    "print(\"Nombre de classes dans JSON COCO:\", num_classes)\n",
    "for c in data[\"categories\"]:\n",
    "    print(c[\"id\"], c[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673da3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_test\")\n",
    "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d0ecc",
   "metadata": {},
   "source": [
    "Si un warning apparait c'est en general car certain label on ete fait avec circle sur labelme. Dans ce cas il faut convertir les cercles en polygone avec la fonction suivante, puis refaire le fichier coco (rerun les cellules ci dessus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import math\n",
    "\n",
    "# # Chemin vers le dossier contenant vos JSON\n",
    "# dossier = \"BubbleIDGit\\\\ProjetBubbleID\\\\training\\\\dataset\\\\val\"\n",
    "\n",
    "# # Nombre de points pour approximater le cercle en polygone\n",
    "# N_POINTS = 50\n",
    "\n",
    "# for nom_fichier in os.listdir(dossier):\n",
    "#     if nom_fichier.endswith(\".json\"):\n",
    "#         chemin_fichier = os.path.join(dossier, nom_fichier)\n",
    "#         with open(chemin_fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "#             try:\n",
    "#                 data = json.load(f)\n",
    "#                 shapes = data.get(\"shapes\", [])\n",
    "#                 for forme in shapes:\n",
    "#                     if forme.get(\"shape_type\") == \"circle\":\n",
    "#                         points = forme.get(\"points\", [])\n",
    "#                         if len(points) >= 2:\n",
    "#                             # On suppose points[0] = centre, points[1] = point sur le cercle\n",
    "#                             cx, cy = points[0]\n",
    "#                             px, py = points[1]\n",
    "#                             r = math.hypot(px - cx, py - cy)\n",
    "\n",
    "#                             # Génération des points du polygone\n",
    "#                             polygon_points = [\n",
    "#                                 [cx + r * math.cos(2 * math.pi * i / N_POINTS),\n",
    "#                                  cy + r * math.sin(2 * math.pi * i / N_POINTS)]\n",
    "#                                 for i in range(N_POINTS)\n",
    "#                             ]\n",
    "\n",
    "#                             # Remplacement des points et du type\n",
    "#                             forme[\"points\"] = polygon_points\n",
    "#                             forme[\"shape_type\"] = \"polygon\"\n",
    "\n",
    "#                 # Réécriture du fichier JSON\n",
    "#                 with open(chemin_fichier, \"w\", encoding=\"utf-8\") as f_out:\n",
    "#                     json.dump(data, f_out, indent=2)\n",
    "\n",
    "#             except json.JSONDecodeError:\n",
    "#                 print(f\"Erreur lecture JSON : {nom_fichier}\")\n",
    "\n",
    "# print(\"Conversion des cercles en polygones terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe08c7",
   "metadata": {},
   "source": [
    "### Visualisation des images avec annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for d in random.sample(train_dataset_dicts, 2):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004d4d4",
   "metadata": {},
   "source": [
    "## Parametres pour le training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = \"./Models\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_MATLAB1.pth\")  # path to the model we just trained\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # 1000 iterations seems good enough for this dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # We have 1 classes.\n",
    "# NOTE: this config means the number of classes, without the background. Do not use num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg) #Create an instance of of DefaultTrainer with the given congiguration\n",
    "#trainer.resume_or_load(resume=False) #Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import detection_utils as utils\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    \n",
    "    mean = 0\n",
    "    std_dev = 25\n",
    "    gaussian_noise = np.random.normal(mean, std_dev, image.shape).astype(np.uint8)\n",
    "    #noisy_image = cv2.add(image, gaussian_noise)\n",
    "    \n",
    "    transform_list = [\n",
    "        #T.Resize((800,600)),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3),\n",
    "        T.RandomSaturation(0.8, 1.4),\n",
    "        #T.RandomRotation(angle=[90, 90]),\n",
    "        #T.RandomNoise(mean=0.0, std=0.1),\n",
    "        T.RandomLighting(0.7),\n",
    "        T.RandomFlip(prob=0.4, horizontal=True, vertical=False),\n",
    "    ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n",
    "trainer=CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff21fc",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc07d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aedcdd",
   "metadata": {},
   "source": [
    "## Save the config to a config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml_path = \"./Models/config.yaml\"\n",
    "with open(config_yaml_path, 'w') as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c1d6d",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "for d in random.sample(val_dataset_dicts, 1):    #select number of images for display\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=val_metadata,\n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(out.get_image()[:,:,::-1])\n",
    "    cv2.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029a21b",
   "metadata": {},
   "source": [
    "## Average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70605701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # ou ton nombre de classes\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "\n",
    "# Ancien modèle\n",
    "cfg.MODEL.WEIGHTS = \"../Customizable/model_final.pth\"\n",
    "predictor_old = DefaultPredictor(cfg)\n",
    "\n",
    "# Nouveau modèle\n",
    "cfg.MODEL.WEIGHTS = \"Models/model_final.pth\"\n",
    "predictor_new = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "\n",
    "\n",
    "\n",
    "metrics_old = inference_on_dataset(predictor_old.model, val_loader, evaluator)\n",
    "print(\"Ancien modèle :\", metrics_old)\n",
    "\n",
    "metrics_new = inference_on_dataset(predictor_new.model, val_loader, evaluator)\n",
    "print(\"Nouveau modèle :\", metrics_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubbleid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
