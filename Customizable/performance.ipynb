{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055b8b48",
   "metadata": {},
   "source": [
    "AP en utilisant 2 coco files pour le tracking performance\n",
    "Il faut creer le fichier d'annotation apres prediction sous le bon format\n",
    "Le fichier gt, doit etre bon c'est celui creer lors de la validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "deb6011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the librairies\n",
    "import cv2, os\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Define the parameters for the model:\n",
    "datasetFolder = r\"C:\\Users\\faraboli\\Desktop\\BubbleID\\BubbleIDGit\\ProjetBubbleID\\training\\DATASETS\\dataset_tip_png\"\n",
    "imagesfolder = os.path.join(datasetFolder, \"val/\")   # Define the path to the folder of images\n",
    "videopath = os.path.join(datasetFolder, \"valVideo.avi\")   # Define the path to the avi video\n",
    "savefolder=\"../training/Output/\"   # Define the folder you want the data to save in\n",
    "savefolder2 = \"../training/Performances_tip/\" \n",
    "extension=\"all_jpg\"    # Define the extension you want all the saved data to have. This should be unique for each experiment\n",
    "thres=0.5    # Define the threshold for what the model identifies as a bubble\n",
    "modelweights = \"..\\\\MODELS\\\\\" + \"Models_3classes_all\" + \"\\\\model_final.pth\"\n",
    "# modelweights=r\"C:\\Users\\faraboli\\Desktop\\BubbleID\\BubbleIDGit\\ProjetBubbleID\\training\\Models_3classes_all\\model_final.pth\"     # Define the path to the saved model weights.\n",
    "# device='cpu'   # Specify if running on \"cpu\" or \"gpu\"\n",
    "device = \"cuda\" if is_available() else \"cpu\"\n",
    "print(f\"Used device : {device}\")\n",
    "\n",
    "\n",
    "validationCOCO_path = os.path.join(datasetFolder, \"val.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b2ddf",
   "metadata": {},
   "source": [
    "Si la video n'existe pas on la creer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50918a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dossier contenant les images\n",
    "\n",
    "fichiers = sorted([f for f in os.listdir(imagesfolder) if f.endswith(\".png\")])\n",
    "N_frame = len(fichiers)\n",
    "\n",
    "\n",
    "if not os.path.exists(videopath):\n",
    "    image_exemple = cv2.imread(os.path.join(imagesfolder, fichiers[0])) # Lire la première image pour obtenir la taille\n",
    "    hauteur, largeur, _ = image_exemple.shape\n",
    "\n",
    "    # Créer l'objet vidéo\n",
    "    fps = 5  # images par seconde\n",
    "    videopath = os.path.join(datasetFolder, \"valVideo.avi\")\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')  # ou 'XVID' pour .avi\n",
    "    video = cv2.VideoWriter(videopath, codec, fps, (largeur, hauteur))\n",
    "\n",
    "    # Ajouter chaque image à la vidéo\n",
    "    for fichier in fichiers:\n",
    "        chemin = os.path.join(imagesfolder, fichier)\n",
    "        image = cv2.imread(chemin)\n",
    "        video.write(image)\n",
    "\n",
    "    # Finaliser\n",
    "    video.release()\n",
    "    print(f\"Vidéo créée : {videopath}\")\n",
    "\n",
    "imagesfolder = os.path.join(datasetFolder, \"trim/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab383f",
   "metadata": {},
   "source": [
    "# Prediction sur le validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "945d4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import BubbleID_My\n",
    "\n",
    "# recharge le module pour prendre en compte les modifications\n",
    "BubbleID_My = importlib.reload(BubbleID_My)\n",
    "\n",
    "import BubbleID_My as BubbleID\n",
    "print(BubbleID.__file__)\n",
    "\n",
    "# Instantiating the class\n",
    "test120=BubbleID.DataAnalysis(imagesfolder,videopath,savefolder,extension,modelweights,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d964371",
   "metadata": {},
   "outputs": [],
   "source": [
    "test120.trimVideo(N_frames_extr=N_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "43edba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data from the images:\n",
    "#test120.set_scale_by_two_points(frame_idx=0, physical_mm=20.0)\n",
    "mm = test120.set_scale_by_two_points(frame_idx=0, physical_mm=20.0, save=True)\n",
    "print(\"mm/px =\", mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "42140252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-22 19:00:08] INFO - checkpoint.py - [Checkpointer] Loading from ..\\MODELS\\Models_3classes_all\\model_final.pth ...\n",
      "100%|██████████| 56/56 [00:06<00:00,  8.59it/s]\n"
     ]
    }
   ],
   "source": [
    "test120.GenerateData(thres, save_rich=True, save_masks=False, save_contours=True, iou_thresh_tid=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28645f8e",
   "metadata": {},
   "source": [
    "# Creation du coco prediction\n",
    "Il faut creer le fichier coco à partir des predictions faites qui soit compatible avec le coco du validation set.\n",
    "On utilise contours_ .json et rich_ .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "536b9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On creer le coco avec les fichier deja existant rich et contour\n",
    "import json, csv\n",
    "\n",
    "\n",
    "contours_json_path = savefolder + 'contours_' + extension + '.json'\n",
    "rich_csv_path = savefolder + 'rich_' + extension + '.csv'\n",
    "outputCoco_path = os.path.join(savefolder2,\"predictions_\" + extension + \".json\")\n",
    "\n",
    "# Lire le fichier JSON d'entrée\n",
    "with open(contours_json_path, 'r', encoding='utf-8') as f_json:\n",
    "    contours = json.load(f_json)\n",
    "\n",
    "# Lire le fichier rich.csv et ne selectionner que les colonne qui nous interressent\n",
    "donnees_filtrees = []\n",
    "\n",
    "with open(rich_csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lecteur = csv.DictReader(f)\n",
    "    for ligne in lecteur:\n",
    "        entree = {\n",
    "            \"frame\": int(ligne[\"frame\"]),\n",
    "            \"det_in_frame\": int(ligne[\"det_in_frame\"]),\n",
    "            \"x1\": int(ligne[\"x1\"]),\n",
    "            \"y1\": int(ligne[\"y1\"]),\n",
    "            \"x2\": int(ligne[\"x2\"]),\n",
    "            \"y2\": int(ligne[\"y2\"]),\n",
    "            \"score\": float(ligne[\"score\"]),\n",
    "            \"class_id\": int(ligne[\"class_id\"])\n",
    "        }\n",
    "        donnees_filtrees.append(entree)\n",
    "\n",
    "\n",
    "if len(donnees_filtrees) != len(contours):\n",
    "    raise(\"Le fichier contours et rich n'ont pas le meme nb de lignes\")\n",
    "\n",
    "outputFile = []\n",
    "for idx, imgCode in enumerate(contours):\n",
    "    # on verifie qu'on parle de la meme image\n",
    "    i, d = map(int, imgCode.split(\"_\"))\n",
    "    if i != (donnees_filtrees[idx][\"frame\"]) or d != (donnees_filtrees[idx][\"det_in_frame\"]):\n",
    "        print(\"WARNING: les 2 fichiers ne sont pas compatibles\")\n",
    "        print(i, donnees_filtrees[idx][\"frame\"], d, donnees_filtrees[idx][\"det_in_frame\"])\n",
    "        continue\n",
    "    \n",
    "    width = (donnees_filtrees[idx][\"x2\"]) - (donnees_filtrees[idx][\"x1\"])\n",
    "    heigth = (donnees_filtrees[idx][\"y2\"]) - (donnees_filtrees[idx][\"y1\"])\n",
    "    flat_coords = [x for pt in contours[imgCode] for x in pt]\n",
    "    prediction = {\n",
    "        \"image_id\": donnees_filtrees[idx][\"frame\"] - 1 , #Dans ce fichier les idx commencent a 1 alors que dans l'autre ils commencent a 0\n",
    "        \"category_id\": donnees_filtrees[idx][\"class_id\"],\n",
    "        \"segmentation\": [flat_coords],\n",
    "        \"score\": donnees_filtrees[idx][\"score\"],\n",
    "        \"bbox\": [donnees_filtrees[idx][\"x1\"], donnees_filtrees[idx][\"y1\"], width, heigth ]\n",
    "    }\n",
    "    outputFile.append(prediction)\n",
    "os.makedirs(savefolder2, exist_ok=True)   \n",
    "# Écrire dans un fichier JSON\n",
    "with open(outputCoco_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(outputFile, f, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bfed8",
   "metadata": {},
   "source": [
    "# Evaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8705fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# --- Charger les fichiers ---\n",
    "annType = 'segm'  # 'bbox' pour détection, 'segm' pour segmentation\n",
    "\n",
    "coco_gt = COCO(validationCOCO_path)       # fichier COCO ground truth\n",
    "coco_dt = coco_gt.loadRes(outputCoco_path)  # fichier prédictions\n",
    "\n",
    "# --- Évaluation ---\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, annType)\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "# --- Capture de la sortie de summarize ---\n",
    "buffer = io.StringIO()\n",
    "sys.stdout = buffer  # Redirige stdout vers le buffer\n",
    "coco_eval.summarize()\n",
    "sys.stdout = sys.__stdout__  # Restaure stdout\n",
    "\n",
    "# --- Sauvegarde dans un fichier texte ---\n",
    "outputResult_path = os.path.join(savefolder2,\"performance_\" + extension + \".json\")\n",
    "\n",
    "with open(outputResult_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubbleid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
